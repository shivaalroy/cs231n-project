{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from wrapper import OASIS\n",
    "from split import split_data\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scans_home = 'data/scans'\n",
    "labels_file = 'data/OASIS3_MRID2Label_052918.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num labels is 2107\n",
      "num filenames is 2193\n",
      "num experiments is 1950\n",
      "counts per class: [1536, 322, 92]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_filenames, val_filenames, test_filenames = split_data(scans_home, labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1365\n",
      "292\n",
      "293\n"
     ]
    }
   ],
   "source": [
    "print(len(train_filenames))\n",
    "print(len(val_filenames))\n",
    "print(len(test_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1075, 225, 65]\n",
      "[230, 48, 14]\n",
      "[231, 49, 13]\n"
     ]
    }
   ],
   "source": [
    "def get_counts(filename_labels):\n",
    "    counts = [0]*3\n",
    "    for filename, label in filename_labels:\n",
    "        counts[label] += 1\n",
    "    return counts\n",
    "\n",
    "print(get_counts(train_filenames))\n",
    "print(get_counts(val_filenames))\n",
    "print(get_counts(test_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished preprocessing\n",
      "mean is 23.00233671815136\n",
      "std is 32.32851956662002\n",
      "finished preprocessing\n",
      "mean is 22.859613037109376\n",
      "std is 33.63062272250271\n",
      "finished preprocessing\n",
      "mean is 23.062867228190104\n",
      "std is 38.60150700491619\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = OASIS(train_filenames[:3])\n",
    "val_dataset = OASIS(val_filenames[:1])\n",
    "test_dataset = OASIS(test_filenames[:1])\n",
    "print([y for img, y in train_dataset])\n",
    "print([y for img, y in val_dataset])\n",
    "print([y for img, y in test_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 299, 299])\n",
      "45\n",
      "15\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "image_array, label = train_dataset[4]\n",
    "print(image_array.shape)\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))\n",
    "save_path = 'test_preview_scan/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_loader = DataLoader(train_dataset, batch_size=10, shuffle=True, num_workers=4)\n",
    "valset_loader = DataLoader(val_dataset, batch_size=10, shuffle=False, num_workers=4)\n",
    "testset_loader = DataLoader(test_dataset, batch_size=10, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available, otherwise stick with cpu\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(123)\n",
    "device = torch.device(cuda if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv.weight False\n",
      "bn.weight False\n",
      "bn.bias False\n",
      "conv.weight False\n",
      "bn.weight False\n",
      "bn.bias False\n",
      "conv.weight False\n",
      "bn.weight False\n",
      "bn.bias False\n",
      "conv.weight False\n",
      "bn.weight False\n",
      "bn.bias False\n",
      "conv.weight False\n",
      "bn.weight False\n",
      "bn.bias False\n",
      "branch1x1.conv.weight False\n",
      "branch1x1.bn.weight False\n",
      "branch1x1.bn.bias False\n",
      "branch5x5_1.conv.weight False\n",
      "branch5x5_1.bn.weight False\n",
      "branch5x5_1.bn.bias False\n",
      "branch5x5_2.conv.weight False\n",
      "branch5x5_2.bn.weight False\n",
      "branch5x5_2.bn.bias False\n",
      "branch3x3dbl_1.conv.weight False\n",
      "branch3x3dbl_1.bn.weight False\n",
      "branch3x3dbl_1.bn.bias False\n",
      "branch3x3dbl_2.conv.weight False\n",
      "branch3x3dbl_2.bn.weight False\n",
      "branch3x3dbl_2.bn.bias False\n",
      "branch3x3dbl_3.conv.weight False\n",
      "branch3x3dbl_3.bn.weight False\n",
      "branch3x3dbl_3.bn.bias False\n",
      "branch_pool.conv.weight False\n",
      "branch_pool.bn.weight False\n",
      "branch_pool.bn.bias False\n",
      "branch1x1.conv.weight False\n",
      "branch1x1.bn.weight False\n",
      "branch1x1.bn.bias False\n",
      "branch5x5_1.conv.weight False\n",
      "branch5x5_1.bn.weight False\n",
      "branch5x5_1.bn.bias False\n",
      "branch5x5_2.conv.weight False\n",
      "branch5x5_2.bn.weight False\n",
      "branch5x5_2.bn.bias False\n",
      "branch3x3dbl_1.conv.weight False\n",
      "branch3x3dbl_1.bn.weight False\n",
      "branch3x3dbl_1.bn.bias False\n",
      "branch3x3dbl_2.conv.weight False\n",
      "branch3x3dbl_2.bn.weight False\n",
      "branch3x3dbl_2.bn.bias False\n",
      "branch3x3dbl_3.conv.weight False\n",
      "branch3x3dbl_3.bn.weight False\n",
      "branch3x3dbl_3.bn.bias False\n",
      "branch_pool.conv.weight False\n",
      "branch_pool.bn.weight False\n",
      "branch_pool.bn.bias False\n",
      "branch1x1.conv.weight False\n",
      "branch1x1.bn.weight False\n",
      "branch1x1.bn.bias False\n",
      "branch5x5_1.conv.weight False\n",
      "branch5x5_1.bn.weight False\n",
      "branch5x5_1.bn.bias False\n",
      "branch5x5_2.conv.weight False\n",
      "branch5x5_2.bn.weight False\n",
      "branch5x5_2.bn.bias False\n",
      "branch3x3dbl_1.conv.weight False\n",
      "branch3x3dbl_1.bn.weight False\n",
      "branch3x3dbl_1.bn.bias False\n",
      "branch3x3dbl_2.conv.weight False\n",
      "branch3x3dbl_2.bn.weight False\n",
      "branch3x3dbl_2.bn.bias False\n",
      "branch3x3dbl_3.conv.weight False\n",
      "branch3x3dbl_3.bn.weight False\n",
      "branch3x3dbl_3.bn.bias False\n",
      "branch_pool.conv.weight False\n",
      "branch_pool.bn.weight False\n",
      "branch_pool.bn.bias False\n",
      "branch3x3.conv.weight False\n",
      "branch3x3.bn.weight False\n",
      "branch3x3.bn.bias False\n",
      "branch3x3dbl_1.conv.weight False\n",
      "branch3x3dbl_1.bn.weight False\n",
      "branch3x3dbl_1.bn.bias False\n",
      "branch3x3dbl_2.conv.weight False\n",
      "branch3x3dbl_2.bn.weight False\n",
      "branch3x3dbl_2.bn.bias False\n",
      "branch3x3dbl_3.conv.weight False\n",
      "branch3x3dbl_3.bn.weight False\n",
      "branch3x3dbl_3.bn.bias False\n",
      "branch1x1.conv.weight False\n",
      "branch1x1.bn.weight False\n",
      "branch1x1.bn.bias False\n",
      "branch7x7_1.conv.weight False\n",
      "branch7x7_1.bn.weight False\n",
      "branch7x7_1.bn.bias False\n",
      "branch7x7_2.conv.weight False\n",
      "branch7x7_2.bn.weight False\n",
      "branch7x7_2.bn.bias False\n",
      "branch7x7_3.conv.weight False\n",
      "branch7x7_3.bn.weight False\n",
      "branch7x7_3.bn.bias False\n",
      "branch7x7dbl_1.conv.weight False\n",
      "branch7x7dbl_1.bn.weight False\n",
      "branch7x7dbl_1.bn.bias False\n",
      "branch7x7dbl_2.conv.weight False\n",
      "branch7x7dbl_2.bn.weight False\n",
      "branch7x7dbl_2.bn.bias False\n",
      "branch7x7dbl_3.conv.weight False\n",
      "branch7x7dbl_3.bn.weight False\n",
      "branch7x7dbl_3.bn.bias False\n",
      "branch7x7dbl_4.conv.weight False\n",
      "branch7x7dbl_4.bn.weight False\n",
      "branch7x7dbl_4.bn.bias False\n",
      "branch7x7dbl_5.conv.weight False\n",
      "branch7x7dbl_5.bn.weight False\n",
      "branch7x7dbl_5.bn.bias False\n",
      "branch_pool.conv.weight False\n",
      "branch_pool.bn.weight False\n",
      "branch_pool.bn.bias False\n",
      "branch1x1.conv.weight False\n",
      "branch1x1.bn.weight False\n",
      "branch1x1.bn.bias False\n",
      "branch7x7_1.conv.weight False\n",
      "branch7x7_1.bn.weight False\n",
      "branch7x7_1.bn.bias False\n",
      "branch7x7_2.conv.weight False\n",
      "branch7x7_2.bn.weight False\n",
      "branch7x7_2.bn.bias False\n",
      "branch7x7_3.conv.weight False\n",
      "branch7x7_3.bn.weight False\n",
      "branch7x7_3.bn.bias False\n",
      "branch7x7dbl_1.conv.weight False\n",
      "branch7x7dbl_1.bn.weight False\n",
      "branch7x7dbl_1.bn.bias False\n",
      "branch7x7dbl_2.conv.weight False\n",
      "branch7x7dbl_2.bn.weight False\n",
      "branch7x7dbl_2.bn.bias False\n",
      "branch7x7dbl_3.conv.weight False\n",
      "branch7x7dbl_3.bn.weight False\n",
      "branch7x7dbl_3.bn.bias False\n",
      "branch7x7dbl_4.conv.weight False\n",
      "branch7x7dbl_4.bn.weight False\n",
      "branch7x7dbl_4.bn.bias False\n",
      "branch7x7dbl_5.conv.weight False\n",
      "branch7x7dbl_5.bn.weight False\n",
      "branch7x7dbl_5.bn.bias False\n",
      "branch_pool.conv.weight False\n",
      "branch_pool.bn.weight False\n",
      "branch_pool.bn.bias False\n",
      "branch1x1.conv.weight False\n",
      "branch1x1.bn.weight False\n",
      "branch1x1.bn.bias False\n",
      "branch7x7_1.conv.weight False\n",
      "branch7x7_1.bn.weight False\n",
      "branch7x7_1.bn.bias False\n",
      "branch7x7_2.conv.weight False\n",
      "branch7x7_2.bn.weight False\n",
      "branch7x7_2.bn.bias False\n",
      "branch7x7_3.conv.weight False\n",
      "branch7x7_3.bn.weight False\n",
      "branch7x7_3.bn.bias False\n",
      "branch7x7dbl_1.conv.weight False\n",
      "branch7x7dbl_1.bn.weight False\n",
      "branch7x7dbl_1.bn.bias False\n",
      "branch7x7dbl_2.conv.weight False\n",
      "branch7x7dbl_2.bn.weight False\n",
      "branch7x7dbl_2.bn.bias False\n",
      "branch7x7dbl_3.conv.weight False\n",
      "branch7x7dbl_3.bn.weight False\n",
      "branch7x7dbl_3.bn.bias False\n",
      "branch7x7dbl_4.conv.weight False\n",
      "branch7x7dbl_4.bn.weight False\n",
      "branch7x7dbl_4.bn.bias False\n",
      "branch7x7dbl_5.conv.weight False\n",
      "branch7x7dbl_5.bn.weight False\n",
      "branch7x7dbl_5.bn.bias False\n",
      "branch_pool.conv.weight False\n",
      "branch_pool.bn.weight False\n",
      "branch_pool.bn.bias False\n",
      "branch1x1.conv.weight False\n",
      "branch1x1.bn.weight False\n",
      "branch1x1.bn.bias False\n",
      "branch7x7_1.conv.weight False\n",
      "branch7x7_1.bn.weight False\n",
      "branch7x7_1.bn.bias False\n",
      "branch7x7_2.conv.weight False\n",
      "branch7x7_2.bn.weight False\n",
      "branch7x7_2.bn.bias False\n",
      "branch7x7_3.conv.weight False\n",
      "branch7x7_3.bn.weight False\n",
      "branch7x7_3.bn.bias False\n",
      "branch7x7dbl_1.conv.weight False\n",
      "branch7x7dbl_1.bn.weight False\n",
      "branch7x7dbl_1.bn.bias False\n",
      "branch7x7dbl_2.conv.weight False\n",
      "branch7x7dbl_2.bn.weight False\n",
      "branch7x7dbl_2.bn.bias False\n",
      "branch7x7dbl_3.conv.weight False\n",
      "branch7x7dbl_3.bn.weight False\n",
      "branch7x7dbl_3.bn.bias False\n",
      "branch7x7dbl_4.conv.weight False\n",
      "branch7x7dbl_4.bn.weight False\n",
      "branch7x7dbl_4.bn.bias False\n",
      "branch7x7dbl_5.conv.weight False\n",
      "branch7x7dbl_5.bn.weight False\n",
      "branch7x7dbl_5.bn.bias False\n",
      "branch_pool.conv.weight False\n",
      "branch_pool.bn.weight False\n",
      "branch_pool.bn.bias False\n",
      "conv0.conv.weight False\n",
      "conv0.bn.weight False\n",
      "conv0.bn.bias False\n",
      "conv1.conv.weight False\n",
      "conv1.bn.weight False\n",
      "conv1.bn.bias False\n",
      "fc.weight False\n",
      "fc.bias False\n",
      "branch3x3_1.conv.weight False\n",
      "branch3x3_1.bn.weight False\n",
      "branch3x3_1.bn.bias False\n",
      "branch3x3_2.conv.weight False\n",
      "branch3x3_2.bn.weight False\n",
      "branch3x3_2.bn.bias False\n",
      "branch7x7x3_1.conv.weight False\n",
      "branch7x7x3_1.bn.weight False\n",
      "branch7x7x3_1.bn.bias False\n",
      "branch7x7x3_2.conv.weight False\n",
      "branch7x7x3_2.bn.weight False\n",
      "branch7x7x3_2.bn.bias False\n",
      "branch7x7x3_3.conv.weight False\n",
      "branch7x7x3_3.bn.weight False\n",
      "branch7x7x3_3.bn.bias False\n",
      "branch7x7x3_4.conv.weight False\n",
      "branch7x7x3_4.bn.weight False\n",
      "branch7x7x3_4.bn.bias False\n",
      "branch1x1.conv.weight False\n",
      "branch1x1.bn.weight False\n",
      "branch1x1.bn.bias False\n",
      "branch3x3_1.conv.weight False\n",
      "branch3x3_1.bn.weight False\n",
      "branch3x3_1.bn.bias False\n",
      "branch3x3_2a.conv.weight False\n",
      "branch3x3_2a.bn.weight False\n",
      "branch3x3_2a.bn.bias False\n",
      "branch3x3_2b.conv.weight False\n",
      "branch3x3_2b.bn.weight False\n",
      "branch3x3_2b.bn.bias False\n",
      "branch3x3dbl_1.conv.weight False\n",
      "branch3x3dbl_1.bn.weight False\n",
      "branch3x3dbl_1.bn.bias False\n",
      "branch3x3dbl_2.conv.weight False\n",
      "branch3x3dbl_2.bn.weight False\n",
      "branch3x3dbl_2.bn.bias False\n",
      "branch3x3dbl_3a.conv.weight False\n",
      "branch3x3dbl_3a.bn.weight False\n",
      "branch3x3dbl_3a.bn.bias False\n",
      "branch3x3dbl_3b.conv.weight False\n",
      "branch3x3dbl_3b.bn.weight False\n",
      "branch3x3dbl_3b.bn.bias False\n",
      "branch_pool.conv.weight False\n",
      "branch_pool.bn.weight False\n",
      "branch_pool.bn.bias False\n",
      "branch1x1.conv.weight False\n",
      "branch1x1.bn.weight False\n",
      "branch1x1.bn.bias False\n",
      "branch3x3_1.conv.weight False\n",
      "branch3x3_1.bn.weight False\n",
      "branch3x3_1.bn.bias False\n",
      "branch3x3_2a.conv.weight False\n",
      "branch3x3_2a.bn.weight False\n",
      "branch3x3_2a.bn.bias False\n",
      "branch3x3_2b.conv.weight False\n",
      "branch3x3_2b.bn.weight False\n",
      "branch3x3_2b.bn.bias False\n",
      "branch3x3dbl_1.conv.weight False\n",
      "branch3x3dbl_1.bn.weight False\n",
      "branch3x3dbl_1.bn.bias False\n",
      "branch3x3dbl_2.conv.weight False\n",
      "branch3x3dbl_2.bn.weight False\n",
      "branch3x3dbl_2.bn.bias False\n",
      "branch3x3dbl_3a.conv.weight False\n",
      "branch3x3dbl_3a.bn.weight False\n",
      "branch3x3dbl_3a.bn.bias False\n",
      "branch3x3dbl_3b.conv.weight False\n",
      "branch3x3dbl_3b.bn.weight False\n",
      "branch3x3dbl_3b.bn.bias False\n",
      "branch_pool.conv.weight False\n",
      "branch_pool.bn.weight False\n",
      "branch_pool.bn.bias False\n",
      "weight True\n",
      "bias True\n"
     ]
    }
   ],
   "source": [
    "inception = torchvision.models.inception_v3(pretrained=True)\n",
    "for i, param in enumerate(inception.parameters()):\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Since imagenet as 1000 classes , We need to change our last layer according to the number of classes we have,\n",
    "n_classes = 3\n",
    "n_features = inception.fc.in_features\n",
    "inception.fc = nn.Linear(n_features, n_classes)\n",
    "\n",
    "\n",
    "for name, child in inception.named_children():\n",
    "    if name == 'fc':\n",
    "        for params in child.parameters():\n",
    "            params.requires_grad = True\n",
    "\n",
    "# Stage-2 , Freeze all the layers till \"Conv2d_4a_3*3\"\n",
    "# ct = []\n",
    "# for name, child in model_conv.named_children():\n",
    "#     print(name)\n",
    "#     if \"Conv2d_4a_3x3\" in ct:\n",
    "#         for params in child.parameters():\n",
    "#             params.requires_grad = True\n",
    "#     ct.append(name)\n",
    "\n",
    "# To view which layers are freeze and which layers are not freezed:\n",
    "for name, child in inception.named_children():\n",
    "    for name_2, params in child.named_parameters():\n",
    "        print(name_2, params.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_parallel = True\n",
    "# if use_parallel:\n",
    "#     print(\"[Using all the available GPUs]\")\n",
    "#     model_conv = nn.DataParallel(model_conv, device_ids=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, use_gpu, num_epochs=5):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                # TODO: wrap them in Variable?\n",
    "                if use_gpu:\n",
    "                    inputs = inputs.cuda()\n",
    "                    labels = labels.cuda()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                if type(outputs) == tuple:\n",
    "                    outputs, _ = outputs\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0]\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.item() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            # TODO: uncomment\n",
    "            # TODO: use a better metric than accuracy?\n",
    "#             if phase == 'val' and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = model.state_dict()\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.46s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0822 Acc: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.06s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1781 Acc: 0.0000\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:12<00:00,  2.44s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0629 Acc: 0.6889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.02s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1329 Acc: 0.0000\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:12<00:00,  2.40s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0502 Acc: 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.02s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1371 Acc: 0.0000\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:12<00:00,  2.41s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0504 Acc: 0.8444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.05s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0983 Acc: 0.4000\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:12<00:00,  2.44s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0450 Acc: 0.8889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1468 Acc: 0.0000\n",
      "\n",
      "Training complete in 1m 21s\n",
      "Best val Acc: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "dataloaders = {'train': trainset_loader, 'val': valset_loader}\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
    "optimizable_params = [param for param in inception.parameters() if param.requires_grad]\n",
    "optimizer = torch.optim.Adam(optimizable_params, lr=0.001)\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "use_gpu = False\n",
    "num_epochs = 5\n",
    "best_model = train_model(inception,\n",
    "                       dataloaders,\n",
    "                       dataset_sizes,\n",
    "                       criterion,\n",
    "                       optimizer,\n",
    "                       exp_lr_scheduler,\n",
    "                       use_gpu,\n",
    "                       num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, testset_loader, test_size, use_gpu):\n",
    "    model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "    predictions = []\n",
    "    # Iterate over data\n",
    "    for inputs, labels in tqdm(testset_loader):\n",
    "        # TODO: wrap them in Variable?\n",
    "        if use_gpu:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        if type(outputs) == tuple:\n",
    "            outputs, _ = outputs\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        predictions.extend(preds.tolist())\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:02<00:02,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 2/2 [00:04<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  0,  0,  0,  0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = evaluate_model(best_model, testset_loader, len(test_dataset), use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.08      1.00      0.14         1\n",
      "          1       1.00      0.08      0.14        13\n",
      "          2       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       0.94      0.20      0.20        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true_y = [y for img, y in test_dataset]\n",
    "true_y[0] = 0\n",
    "predictions[1] = 1\n",
    "true_y[2] = 2\n",
    "predictions[2] = 2\n",
    "print(true_y)\n",
    "print(predictions)\n",
    "print(classification_report(true_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
